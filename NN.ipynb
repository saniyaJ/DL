{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to between 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model = keras.Sequential(\n",
    "  [ layers.Flatten(input_shape=(28,28)),\n",
    "   layers.Dense(128,activation ='relu'),\n",
    "   layers.Dropout(0.2),\n",
    "   layers.Dense(10,activation='softmax')   \n",
    "  ]\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',  # Sparse categorical cross-entropy for integer labels\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp39-cp39-win_amd64.whl (172.4 MB)\n",
      "     -------------------------------------- 172.4/172.4 MB 5.3 MB/s eta 0:00:00\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 5.3 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.3-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, networkx, MarkupSafe, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-2.1.3 filelock-3.12.4 jinja2-3.1.2 mpmath-1.3.0 networkx-3.1 sympy-1.12 torch-2.0.1 typing-extensions-4.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'c:\\Users\\sj36580\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'c:\\Users\\sj36580\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\sj36580\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-1.26.0-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "     ---------------------------------------- 15.8/15.8 MB 9.1 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.26.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\sj36580\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\sj36580\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 5.8 MB/s eta 0:00:00\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-10.0.1-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 8.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\sj36580\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (1.26.0)\n",
      "Collecting requests\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\sj36580\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\sj36580\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==2.0.1->torchvision) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sj36580\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\sj36580\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==2.0.1->torchvision) (3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sj36580\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==2.0.1->torchvision) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sj36580\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==2.0.1->torchvision) (4.8.0)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "     -------------------------------------- 158.3/158.3 KB 9.3 MB/s eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.0.5-py3-none-any.whl (123 kB)\n",
      "     -------------------------------------- 123.8/123.8 KB 7.1 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.2.0-cp39-cp39-win_amd64.whl (96 kB)\n",
      "     ---------------------------------------- 96.9/96.9 KB ? eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sj36580\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sj36580\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
      "Installing collected packages: urllib3, pillow, idna, charset-normalizer, certifi, requests, torchvision\n",
      "Successfully installed certifi-2023.7.22 charset-normalizer-3.2.0 idna-3.4 pillow-10.0.1 requests-2.31.0 torchvision-0.15.2 urllib3-2.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\sj36580\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\sj36580\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear,Flatten,CrossEntropyLoss,Module,ReLU,Dropout\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist(Module):\n",
    "    def __init__(self):\n",
    "        super(mnist, self).__init__()\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1= Linear(28*28,128)\n",
    "        self.relu = ReLU()\n",
    "        self.fc2 = Linear(128,10)\n",
    "    def forward(self,x):\n",
    "        x=self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model=mnist()\n",
    "cirterion = CrossEntropyLoss()\n",
    "optimizr = optim.Adam(model.parameters(),lr=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 400, Loss: 0.425\n",
      "Epoch 1, Batch 800, Loss: 0.443\n",
      "Epoch 2, Batch 400, Loss: 0.436\n",
      "Epoch 2, Batch 800, Loss: 0.424\n",
      "Epoch 3, Batch 400, Loss: 0.420\n",
      "Epoch 3, Batch 800, Loss: 0.443\n",
      "Epoch 4, Batch 400, Loss: 0.425\n",
      "Epoch 4, Batch 800, Loss: 0.422\n",
      "Epoch 5, Batch 400, Loss: 0.436\n",
      "Epoch 5, Batch 800, Loss: 0.412\n",
      "Epoch 6, Batch 400, Loss: 0.413\n",
      "Epoch 6, Batch 800, Loss: 0.452\n",
      "Epoch 7, Batch 400, Loss: 0.378\n",
      "Epoch 7, Batch 800, Loss: 0.439\n",
      "Epoch 8, Batch 400, Loss: 0.419\n",
      "Epoch 8, Batch 800, Loss: 0.418\n",
      "Epoch 9, Batch 400, Loss: 0.403\n",
      "Epoch 9, Batch 800, Loss: 0.430\n",
      "Epoch 10, Batch 400, Loss: 0.403\n",
      "Epoch 10, Batch 800, Loss: 0.409\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for i,data in enumerate(train_loader):\n",
    "        input,label = data\n",
    "        optimizr.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = cirterion(output,label)\n",
    "        loss.backward()\n",
    "        optimizr.step()\n",
    "        running_loss +=loss.item()\n",
    "        if i % 400 == 399:  # Print every 200 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 200:.3f}')\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.20%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "correct = 0\n",
    "total = 0\n",
    "y_pred =[]\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest probability\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {(correct / total) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 200, Loss: 2.765\n",
      "Epoch 1, Batch 400, Loss: 1.727\n",
      "Epoch 1, Batch 600, Loss: 1.642\n",
      "Epoch 2, Batch 200, Loss: 3.005\n",
      "Epoch 2, Batch 400, Loss: 1.533\n",
      "Epoch 2, Batch 600, Loss: 1.520\n",
      "Epoch 3, Batch 200, Loss: 2.808\n",
      "Epoch 3, Batch 400, Loss: 1.452\n",
      "Epoch 3, Batch 600, Loss: 1.459\n",
      "Epoch 4, Batch 200, Loss: 2.725\n",
      "Epoch 4, Batch 400, Loss: 1.436\n",
      "Epoch 4, Batch 600, Loss: 1.416\n",
      "Epoch 5, Batch 200, Loss: 2.609\n",
      "Epoch 5, Batch 400, Loss: 1.354\n",
      "Epoch 5, Batch 600, Loss: 1.400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def cifar_model(Module):\n",
    "    def __init__(self):\n",
    "        super(cifar_model,self).__init__()\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1=Linear(32*32,1024)\n",
    "        self.relu=ReLU()\n",
    "        self.fc2=Linear(1024,256)\n",
    "        self.fc3=Linear(256,10)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.flatten(x)\n",
    "        x=self.fc1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 64 * 16 * 16)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "cirterion = CrossEntropyLoss()\n",
    "optimizr = optim.Adam(model.parameters(),lr=0.01)\n",
    "\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        input,label = data\n",
    "        total_loss =0\n",
    "        optimizr.zero_grad()\n",
    "\n",
    "        output = model(input)\n",
    "        loss = cirterion(output,label)\n",
    "        loss.backward()\n",
    "        optimizr.step()\n",
    "\n",
    "        running_loss+=loss.item()\n",
    "        if i % 300 == 299:  # Print every 200 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 200:.3f}')\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 46.00%\n"
     ]
    }
   ],
   "source": [
    "correct =0\n",
    "total =0\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {(correct / total) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.nn import ReLU , Conv2d,Dropout,Flatten, MaxPool2d,Flatten,Linear,CrossEntropyLoss\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "tranform  = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=tranform)\n",
    "train_loader = DataLoader(train_set,batch_size=batch_size,shuffle=True)\n",
    "#32*32 images . 60K\n",
    "#6000 images per class\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=tranform)\n",
    "test_loader = DataLoader(test_set,batch_size=batch_size,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.Adagrad(model.parameters(),lr=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
