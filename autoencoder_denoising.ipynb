{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfbYxxVY2DDK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.nn import Sequential,Linear,ReLU,Tanh,Sigmoid,L1Loss,MSELoss,Softmax,CrossEntropyLoss\n",
        "criterion = CrossEntropyLoss()\n",
        "from torch.optim import Adam\n",
        "import torchvision.datasets as dataset\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#enable cuda\n",
        "device = 'cpu' if torch.cuda.is_available() else 'cuda:0'\n",
        "device"
      ],
      "metadata": {
        "id": "IqpIn5jb2Hqp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7c3bcf89-75da-4be2-ba8e-4d2a32ce2348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load data\n",
        "train_data = dataset.MNIST(root='./data',train=True,transform =transforms.ToTensor(),download=True )\n",
        "test_data = dataset.MNIST(root='./data',train=False,transform =transforms.ToTensor(),download=True )\n",
        "train_loader = DataLoader(dataset = train_data,batch_size=32,shuffle=True)\n",
        "test_loader = DataLoader(dataset = test_data,batch_size=32,shuffle=True)\n",
        "input_size = 28*28\n",
        "print(train_data.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbRS4CKZ2INv",
        "outputId": "4cd1ed88-f45b-40d6-e91f-a702dfd73bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#784 --> 128 ---> 64 --> 36--->36 ---> 64 ---> 128 ---> 784\n",
        "class denoise_auto_encoder(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  \n",
        "  \n",
        "    self.encoder = Sequential(\n",
        "          Linear(input_size,128),\n",
        "          ReLU(),\n",
        "          Linear(128,64),\n",
        "          ReLU(),\n",
        "          Linear(64,36)\n",
        "          \n",
        "      )\n",
        "    self.decoder = Sequential(\n",
        "          Linear(36,64),\n",
        "          ReLU(),\n",
        "          Linear(64,128),\n",
        "          ReLU(),\n",
        "          Linear(128,input_size),\n",
        "          Sigmoid()\n",
        "      )\n",
        "\n",
        "  def forward(self,input):\n",
        "    enc= self.encoder(input)\n",
        "    dec = self.decoder(enc)\n",
        "    return enc,dec\n"
      ],
      "metadata": {
        "id": "Hi1LJYl45lJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(loss):\n",
        "  \n",
        "  plt.style.use('fivethirtyeight')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss') \n",
        "  \n",
        "  plt.plot(loss[-100:])\n",
        "\n",
        "\n",
        "def train_denoising(model,optimizer,epochs,loss_fun,data_loader,input_size):\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    try:\n",
        "      noise_factor=0.2\n",
        "      epoch_loss=[]\n",
        "      i=0\n",
        "      for (image, label) in data_loader:\n",
        "        image = image.reshape(-1, input_size)\n",
        "        ## add random noise to the input images\n",
        "        noisy_imgs = image + noise_factor * torch.randn(*image.shape)\n",
        "        # Clip the images to be between 0 and 1\n",
        "        noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
        "\n",
        "        image = noisy_imgs.to(device)        \n",
        "        encoder_output,decoder_output = model(image)\n",
        "        if i==0:\n",
        "          encoder_output_list = encoder_output.detach().numpy()\n",
        "          label_list = label.detach().numpy()\n",
        "        else:\n",
        "          encoder_output_list = np.append(encoder_output_list,encoder_output,axis=0)\n",
        "          label_list = np.append(label_list,label)\n",
        "\n",
        "        # Calculating the loss function\n",
        "        loss = loss_fun(decoder_output, image)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Storing the losses in a list for plotting\n",
        "        losses.append(loss)\n",
        "        epoch_loss.append(loss)\n",
        "        if epoch+1 == epochs: \n",
        "          output.append((epochs, image, decoder_output))\n",
        "        print('epoch [{}], loss:{:.4f}'\n",
        "            .format(epoch + 1, np.mean(epoch_loss)))\n",
        "        print('entered try')\n",
        "        scalled_encoder = StandardScaler().fit_transform(encoder_output_list)\n",
        "\n",
        "      \n",
        "        tsne = TSNE(n_components=2,metric='euclidean',random_state=100,\n",
        "                    perplexity=np.sqrt(np.round(len(scalled_encoder),0)),learning_rate=10,\n",
        "                    n_iter=1000,n_iter_without_progress=300,\n",
        "                    min_grad_norm=1e-7,n_jobs=-1) \n",
        "      \n",
        "      tsne_embedded = tsne.fit_transform(scalled_encoder)  \n",
        "      return model,tsne_embedded,encoder_output_list,decoder_output,label_list\n",
        "    except Exception as e: print(e)\n",
        "\n",
        "    # finally:\n",
        "    #   plot_loss(losses)\n",
        "    #   return model\n",
        "      \n",
        "\n",
        "\n",
        "#extracting encoer and adding classification layer\n",
        "class classifier(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \n",
        "    #Encoder layers\n",
        "    self.layer = Sequential(\n",
        "        Linear(36,10),\n",
        "        Softmax(1)\n",
        "    )\n",
        "   \n",
        "  def forward(self, x):\n",
        "    #Forward prop\n",
        "    x = self.layer(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "kDxMlOdo5uTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mae_loss = MSELoss()\n",
        "\n",
        "model = denoise_auto_encoder().cuda()\n",
        "optimizer = Adam(model.parameters(),lr = .01,weight_decay =1e-5)\n",
        "epochs =10\n",
        "output = []\n",
        "losses = []\n",
        "model,tsme_emdeded,encoder_train,decoder_train,labels = train_denoising(model,optimizer,epochs,mae_loss,train_loader,input_size)\n",
        "\n",
        "ax1 = sns.scatterplot(x=tsme_emdeded[:,0],y=tsme_emdeded[:,1],hue=labels)\n",
        "ax1.set(xlabel='tsne-0',ylabel='tsne-1',title='tsne-0 vs tsne-1')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "ZuPlOnBR5hgr",
        "outputId": "613ecc98-120e-4b59-cd7c-01560eb26de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)\n",
            "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)\n",
            "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)\n",
            "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)\n",
            "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)\n",
            "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)\n",
            "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)\n",
            "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)\n",
            "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)\n",
            "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d84cd8a07124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtsme_emdeded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_denoising\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmae_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# ax = sns.lineplot(x=range(epochs),y=train_loss_standard,color='r')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# ax = sns.lineplot(x=range(epochs),y=valid_loss_standard,color='g')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier(model,optimizer,epochs,loss_fun,data_loader,input_size):\n",
        "  for epoch in range(epochs):\n",
        "    try:\n",
        "      epoch_loss=[]\n",
        "      i=0\n",
        "      for (image, label) in data_loader:\n",
        "        image = image.reshape(-1, input_size)\n",
        "        ## add random noise to the input images\n",
        "        image = image.to(device)        \n",
        "        output = model(image)\n",
        "        # if i==0:\n",
        "        #   encoder_output_list = output.detach().numpy()\n",
        "        #   label_list = label.detach().numpy()\n",
        "        # else:\n",
        "        #   encoder_output_list = np.append(encoder_output_list,output,axis=0)\n",
        "        #   label_list = np.append(label_list,label)\n",
        "\n",
        "        # Calculating the loss function\n",
        "        loss = loss_fun(output, label.long())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Storing the losses in a list for plotting\n",
        "        losses.append(loss)\n",
        "        epoch_loss.append(loss)\n",
        "        if epoch+1 == epochs: \n",
        "          output.append((epochs, image, decoder_output))\n",
        "        print('epoch [{}], loss:{:.4f}'\n",
        "            .format(epoch + 1, np.mean(epoch_loss)))\n",
        "        print('entered try')\n",
        "    return model\n",
        "    except Exception as e: print(e)\n"
      ],
      "metadata": {
        "id": "YKHCTmChm0AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_x = torch.Tensor(encoder_train) # transform to torch tensor\n",
        "tensor_y = torch.Tensor(labels)\n",
        "new_dataset = TensorDataset(tensor_x,tensor_y) \n",
        "classifier_loader = DataLoader(new_dataset, batch_size=32) \n",
        "criterion = CrossEntropyLoss()\n",
        "clasifier_model = classifier()\n",
        "\n",
        "model = train_classifier(clasifier_model,optimizer,epochscriterion,classifier_loader,input_size)"
      ],
      "metadata": {
        "id": "bq6pgCL3dj8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B3iMtBoiJ_lC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}